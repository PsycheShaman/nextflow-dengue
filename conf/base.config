/*
 * -------------------------------------------------
 *  Base config file with default process parameters
 * -------------------------------------------------
 * 
 * This configuration file defines the default parameters for all processes
 * in the pipeline. It includes:
 * - Default resource requirements
 * - Process labels for different resource tiers
 * - Error handling strategies
 * - Output directory structure
 */

process {
    // Default publishDir settings
    // Controls how output files are saved
    publishDir = [
        // Dynamic path based on process name
        path: { "${params.outdir}/${task.process.tokenize(':')[-1].toLowerCase()}" },
        mode: 'copy',    // Copy files instead of linking
        saveAs: { filename -> 
            // Don't publish versions.yml files
            filename.equals('versions.yml') ? null : filename 
        }
    ]

    // Default Computing Resources
    // These are the base resources allocated to each process
    // The values can be increased by task.attempt for automatic retry with more resources
    cpus = { check_max( 1 * task.attempt, 'cpus' ) }     // Start with 1 CPU, scale up on retry
    memory = { check_max( 6.GB * task.attempt, 'memory' ) } // Start with 6GB, scale up on retry
    time = { check_max( 4.h * task.attempt, 'time' ) }    // Start with 4 hours, scale up on retry

    // Error Handling Strategy
    // Defines how to handle process failures
    errorStrategy = { 
        // Retry on specific error codes that typically indicate resource issues
        task.exitStatus in [143,137,104,134,139] ? 'retry' : 'finish' 
    }
    maxRetries = 3      // Maximum number of retries per process
    maxErrors = '-1'    // No limit on number of errors

    // Process-Specific Resource Labels
    // These labels can be applied to processes to assign specific resource tiers
    
    // Light-weight processes (e.g., FastQC, basic file operations)
    withLabel:process_low {
        cpus = { check_max( 2 * task.attempt, 'cpus' ) }     // 2 CPUs
        memory = { check_max( 12.GB * task.attempt, 'memory' ) } // 12GB RAM
        time = { check_max( 4.h * task.attempt, 'time' ) }    // 4 hours
    }
    
    // Medium-weight processes (e.g., read alignment, variant calling)
    withLabel:process_medium {
        cpus = { check_max( 6 * task.attempt, 'cpus' ) }     // 6 CPUs
        memory = { check_max( 36.GB * task.attempt, 'memory' ) } // 36GB RAM
        time = { check_max( 8.h * task.attempt, 'time' ) }    // 8 hours
    }
    
    // Heavy-weight processes (e.g., de novo assembly)
    withLabel:process_high {
        cpus = { check_max( 12 * task.attempt, 'cpus' ) }    // 12 CPUs
        memory = { check_max( 72.GB * task.attempt, 'memory' ) } // 72GB RAM
        time = { check_max( 16.h * task.attempt, 'time' ) }   // 16 hours
    }
    
    // Long-running processes
    withLabel:process_long {
        time = { check_max( 20.h * task.attempt, 'time' ) }   // 20 hours
    }
    
    // Memory-intensive processes
    withLabel:process_high_memory {
        memory = { check_max( 200.GB * task.attempt, 'memory' ) } // 200GB RAM
    }
    
    // Special error handling labels
    withLabel:error_ignore {
        errorStrategy = 'ignore'    // Continue pipeline even if this process fails
    }
    withLabel:error_retry {
        errorStrategy = 'retry'     // Retry failed processes
        maxRetries = 2             // Maximum 2 retries
    }
} 